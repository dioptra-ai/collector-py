{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d72647-2d50-4c30-be53-67d1bd71eb68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install dioptra\n",
    "# Restart the kernel for this to take effect\n",
    "import dioptra\n",
    "print('dioptra version:', dioptra.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d0f32-18d8-47ab-a372-9978214d1fcd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets torchvision transformers evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2a299-a6a1-4513-9bb1-0b215d8985ed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e838d-9cc3-4613-9016-5520ae0f9c14",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f83722-a089-46cc-b77a-d5a62a433452",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b4a52-0b7a-4066-aefd-485ad32ed1cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from dioptra.inference.torch.torch_runner import TorchInferenceRunner\n",
    "from dioptra.lake.utils import select_datapoints, delete_datapoints\n",
    "from dioptra.lake.datasets import Dataset as DioptraDataset\n",
    "from dioptra.miners.random_miner import RandomMiner\n",
    "from dioptra.miners.weighted_entropy_miner import WeightedEntropyMiner\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# import yolov7 specific things\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import yaml\n",
    "from utils.torch_utils import torch_distributed_zero_first\n",
    "from utils.datasets import letterbox, LoadImagesAndLabels\n",
    "from utils.general import non_max_suppression_mask_conf\n",
    "from models.experimental import attempt_load\n",
    "from detectron2.modeling.poolers import ROIPooler\n",
    "from detectron2.structures import Boxes\n",
    "from detectron2.utils.memory import retry_if_cuda_oom\n",
    "from detectron2.layers import paste_masks_in_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79047a35-577c-4cd4-b533-284866712320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_bucket = 'YOUR BUCKET NAME'\n",
    "img_dir = f's3://{img_bucket}/instance_seg/cocoval'\n",
    "method = 'weighted_entropy'\n",
    "# Jerry's dev org\n",
    "os.environ['DIOPTRA_API_KEY'] = 'YOUR API KEY HERE'\n",
    "os.environ['DIOPTRA_UPLOAD_BUCKET'] = img_bucket\n",
    "os.environ['DIOPTRA_UPLOAD_PREFIX'] = '/media/logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bc43c-4c37-4300-a8d6-8ba340dd3d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!aws s3 cp ./coco/images/val2017 {img_dir} --recursive --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b539f-a0e1-4158-8735-28c7729569dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_img_dir = './coco/images/val2017'\n",
    "dirlist = os.listdir(local_img_dir)\n",
    "files = []\n",
    "for item in dirlist:\n",
    "    file_name = os.path.join(local_img_dir, item)\n",
    "    if os.path.isfile(file_name):\n",
    "        files.append(file_name)\n",
    "\n",
    "n = len(files)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ac7a7-cce6-468d-b5bb-e8bf116c5042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do some yolo7 stuff\n",
    "from utils.general import check_file, check_img_size\n",
    "with open('data/hyp.scratch.mask.yaml') as f:\n",
    "    hyp = yaml.load(f, Loader=yaml.FullLoader)\n",
    "model = attempt_load('yolov7-mask.pt')\n",
    "model = model.to(device)\n",
    "_ = model.eval()\n",
    "names = model.names\n",
    "pooler_scale = model.pooler_scale\n",
    "pooler = ROIPooler(output_size=hyp['mask_resolution'], scales=(pooler_scale,), sampling_ratio=1, pooler_type='ROIAlignV2', canonical_level=2)\n",
    "\n",
    "batch_size = 5\n",
    "gs = max(int(model.stride.max()), 32)\n",
    "imgsz = check_img_size(640, gs)\n",
    "cfg = check_file('./cfg/yolov7-mask.yaml')\n",
    "num_workers = 8\n",
    "world_size = int(os.environ['WORLD_SIZE']) if 'WORLD_SIZE' in os.environ else 1\n",
    "global_rank = int(os.environ['RANK']) if 'RANK' in os.environ else -1\n",
    "rank = global_rank\n",
    "rect = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3d445-101b-4553-8535-d90e0f25c49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def _get_layer_by_name(model, name):\n",
    "    split = name.split('.')\n",
    "    current_layer = model\n",
    "    for part in split:\n",
    "        if re.match('\\[[0-9-]+\\]', part):\n",
    "            index = int(part.replace('[', '').replace(']', ''))\n",
    "            current_layer = current_layer[index]\n",
    "        else:\n",
    "            current_layer = getattr(current_layer, part)\n",
    "    return current_layer\n",
    "\n",
    "print(_get_layer_by_name(model, 'model.128'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4aa2e-55c5-4cf0-bf7f-87dcbbb32a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build a modified yolov7 dataloader\n",
    "\n",
    "# it needs to be a finite dataloader as we are inferring over a set of points\n",
    "def create_dataloader(path, imgsz, batch_size, stride, hyp=None, augment=False, cache=False, pad=0.0, rect=False,\n",
    "                      rank=-1, world_size=1, workers=8, image_weights=False, quad=False, prefix='', shuffle = False, finite = False):\n",
    "    with torch_distributed_zero_first(rank):\n",
    "        dataset = LoadImagesAndLabels(path, imgsz, batch_size,\n",
    "                                      augment=augment,  # augment images\n",
    "                                      hyp=hyp,  # augmentation hyperparameters\n",
    "                                      rect=rect,  # rectangular training\n",
    "                                      cache_images=cache,\n",
    "                                      single_cls=False,\n",
    "                                      stride=int(stride),\n",
    "                                      pad=pad,\n",
    "                                      image_weights=image_weights,\n",
    "                                      prefix=prefix)\n",
    "\n",
    "    batch_size = min(batch_size, len(dataset))\n",
    "    nw = min([os.cpu_count() // world_size, batch_size if batch_size > 1 else 0, workers])  # number of workers\n",
    "    if finite or image_weights:\n",
    "        loader = torch.utils.data.DataLoader\n",
    "    dataloader = loader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=nw,\n",
    "                        shuffle=shuffle,\n",
    "                        pin_memory=True,\n",
    "                        collate_fn=LoadImagesAndLabels.collate_fn)\n",
    "    return dataloader, dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8e690-1c9e-4896-9c7b-934c46f53ba8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate the metadata for the images\n",
    "from tqdm import tqdm\n",
    "test_path = './coco/val2017.txt'\n",
    "\n",
    "dataloader, dataset = create_dataloader(test_path, imgsz, batch_size, gs,\n",
    "                                            hyp=hyp, augment=False, cache=True, rect=rect, rank=rank,\n",
    "                                            world_size=world_size, workers=num_workers,\n",
    "                                            image_weights=[], quad=False, shuffle=False, finite = True)\n",
    "\n",
    "num_range = [i for i in range(50)]\n",
    "\n",
    "_inds = num_range\n",
    "if _inds is not None:\n",
    "    dataset.imgs = [dataset.imgs[i] for i in _inds]\n",
    "    dataset.img_files = [dataset.img_files[i] for i in _inds]\n",
    "    dataset.label_files = [dataset.label_files[i] for i in _inds]\n",
    "    dataset.labels = [dataset.labels[i] for i in _inds]\n",
    "    dataloader.dataset.imgs = dataset.imgs\n",
    "    dataloader.dataset.img_files = dataset.img_files\n",
    "    dataloader.dataset.label_files = dataset.label_files\n",
    "    dataloader.dataset.labels = dataset.labels\n",
    "\n",
    "\n",
    "metadata = []\n",
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc='Creating metadata')):\n",
    "    for i in range(len(paths)):\n",
    "        image = cv2.imread(paths[i])\n",
    "        image = letterbox(image, 640, stride=64, auto=True)[0]\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = torch.tensor(np.array([image.numpy()]))\n",
    "\n",
    "        file_name = paths[i].split('/')[-1]\n",
    "        uri = os.path.join(img_dir, file_name)\n",
    "        _, _, height, width = image.shape\n",
    "        metadata.append({'image_metadata': {'uri': uri, 'width': width, 'height': height}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234c229-ef4e-48b9-86df-18f1abc30910",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install imantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70840b29-1479-4fae-a64e-b131e71b5ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_resolution = (5,5)\n",
    "def logits_transformer(logits, embeddings, model, pooler, hyp, metadata = []):\n",
    "    # Assumes model being used has an MT head\n",
    "    raw_prediction = logits['test']\n",
    "    train_out = logits['bbox_and_cls']\n",
    "    attn = logits['attn']\n",
    "    mask_iou = logits['mask_iou']\n",
    "    bases = logits['bases']\n",
    "    sem = logits['sem']\n",
    "    record = {}\n",
    "    sem_bases = torch.cat([bases, sem], dim=1)\n",
    "    names = model.names\n",
    "    pooler_scale = model.pooler_scale\n",
    "    \n",
    "    output, output_mask, output_mask_score, output_ac, output_ab = non_max_suppression_mask_conf(raw_prediction, attn, bases,\n",
    "                                                                        pooler, hyp, conf_thres=0.25, iou_thres=0.65,\n",
    "                                                                        merge=False, mask_iou=None)\n",
    "    # BELOW: nms threshold values are based on active learning experiments\n",
    "    # output, output_mask, output_mask_score, output_ac, output_ab = non_max_suppression_mask_conf(raw_prediction, attn, bases,\n",
    "    #                                                                     pooler, hyp, conf_thres=0.001332, iou_thres=0.3,\n",
    "    #                                                                     merge=False, mask_iou=None)\n",
    "\n",
    "    records = []\n",
    "    for i in range(len(output)): #iterate over each image\n",
    "        record = {}\n",
    "        record['task_type'] = 'INSTANCE_SEGMENTATION'\n",
    "        record['model_name'] = 'yolov7==0.1' #version of the model\n",
    "\n",
    "        pred, pred_masks = output[i], output_mask[i]\n",
    "        metrics = calc_metrics(raw_prediction[i,...])\n",
    "        height = metadata[i]['image_metadata']['height']\n",
    "        width = metadata[i]['image_metadata']['width']\n",
    "        #calculate shift for each box dimension\n",
    "        width_shift = (640 - width) / 2\n",
    "        height_shift = (640 - height) / 2\n",
    "        base = sem_bases[i]\n",
    "        bbox_list = []\n",
    "        if pred is not None:\n",
    "            boxes = pred[:,:4]\n",
    "            # # truncate box to correct size\n",
    "            for i in range(len(boxes)):\n",
    "                if boxes[i][0] > width:\n",
    "                    boxes[i][0] = torch.clamp(boxes[i][0], 0, width)\n",
    "                if boxes[i][1] > height:\n",
    "                    boxes[i][1] = torch.clamp(boxes[i][1], 0, height)\n",
    "                if boxes[i][2] > width:\n",
    "                    boxes[i][2] = torch.clamp(boxes[i][2], 0, width)\n",
    "                if boxes[i][3] > height:\n",
    "                    boxes[i][3] = torch.clamp(boxes[i][3], 0, height)\n",
    "            bboxes = Boxes(boxes)\n",
    "            pooled_bases = pooler([base[None]], [bboxes])\n",
    "            pooled_bases = torch.nn.functional.interpolate(pooled_bases, embedding_resolution, mode=\"bilinear\")\n",
    "            pooled_bases = pooled_bases.flatten(start_dim=1).cpu().numpy()\n",
    "            original_pred_masks = pred_masks.view(-1, hyp['mask_resolution'], hyp['mask_resolution'])\n",
    "            pred_masks = retry_if_cuda_oom(paste_masks_in_image)( original_pred_masks, bboxes, (height,width), threshold=0.5)\n",
    "            pred_masks_np = pred_masks.detach().cpu().numpy()\n",
    "            pred_cls = pred[:, 5].detach().cpu().numpy()\n",
    "            pred_conf = pred[:, 4].detach().cpu().numpy()\n",
    "            nbboxes = bboxes.tensor.detach().cpu().numpy().astype(int)\n",
    "            # output is in record format with task type, model_name, bboxes\n",
    "            # bboxes is list of dicts with class_names, confidences, segmentation_mask, objectness\n",
    "            for one_mask, bbox, cls_name, conf, embedding in zip(pred_masks_np, nbboxes, pred_cls, pred_conf, pooled_bases):\n",
    "                if conf < 0.25:\n",
    "                    continue\n",
    "\n",
    "                item = {'top': int(bbox[1] - height_shift),\n",
    "                    'left': int(bbox[0] - width_shift),\n",
    "                    'height': int(bbox[3] - bbox[1]),\n",
    "                    'width': int(bbox[2] - bbox[0]),\n",
    "                    'class_name': names[int(cls_name)],\n",
    "                    'confidence': float(conf),\n",
    "                    'embedding': embedding.tolist(),\n",
    "                }\n",
    "                bbox_list.append(item)\n",
    "        record['bboxes'] = bbox_list\n",
    "        record['metrics'] = {'weighted_entropy': float(metrics)}\n",
    "        records.append(record)\n",
    "    return records\n",
    "\n",
    "def calc_metrics(prediction):\n",
    "    confs = prediction[...,4:5]*prediction[...,5:]\n",
    "    entropy = torch.special.entr(confs)\n",
    "    return np.sum(entropy.cpu().numpy())\n",
    "\n",
    "def data_transformer(batch):\n",
    "    return batch[0].float()/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de98634-0751-4982-b8b1-084340e09eb1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "\n",
    "delete_datapoints([])\n",
    "test_path = './coco/val2017.txt'\n",
    "dataloader, dataset = create_dataloader(test_path, imgsz, batch_size, gs,\n",
    "                                            hyp=hyp, augment=False, cache=True, rect=rect, rank=rank,\n",
    "                                            world_size=world_size, workers=num_workers,\n",
    "                                            image_weights=[], quad=False, shuffle=False, finite = True)\n",
    "num_range = [i for i in range(50)]\n",
    "\n",
    "#Assumes roi function input is the ROI Pooler from Detectron 2\n",
    "pooler_scale = model.pooler_scale\n",
    "pooler = ROIPooler(output_size=hyp['mask_resolution'], scales=(pooler_scale,),\n",
    "                   sampling_ratio=1, pooler_type='ROIAlignV2', canonical_level=2)\n",
    "\n",
    "_inds = num_range\n",
    "if _inds is not None:\n",
    "    dataset.imgs = [dataset.imgs[i] for i in _inds]\n",
    "    dataset.img_files = [dataset.img_files[i] for i in _inds]\n",
    "    dataset.label_files = [dataset.label_files[i] for i in _inds]\n",
    "    dataset.labels = [dataset.labels[i] for i in _inds]\n",
    "    dataloader.dataset.imgs = dataset.imgs\n",
    "    dataloader.dataset.img_files = dataset.img_files\n",
    "    dataloader.dataset.label_files = dataset.label_files\n",
    "    dataloader.dataset.labels = dataset.labels\n",
    "\n",
    "runner = TorchInferenceRunner(\n",
    "    model = model,\n",
    "    model_type='INSTANCE_SEGMENTATION',\n",
    "    model_name = 'yolov7',\n",
    "    data_transform = data_transformer,\n",
    "    datapoints_metadata=metadata,\n",
    "    logits_layer='model.128',\n",
    "    class_names=names,\n",
    "    logits_transform=partial(logits_transformer, model = model, pooler=pooler, hyp = hyp),\n",
    "    channel_last=False,\n",
    ")\n",
    "runner.max_batch_size = batch_size - 1\n",
    "runner.run(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9729c6-257e-46ad-9e83-c84faa6645ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "filters=[{\n",
    "    'left': 'predictions.model_name',\n",
    "    'op': '=',\n",
    "    'right': 'yolov7'\n",
    "}]\n",
    "if method == 'weighted_entropy':\n",
    "    miner = WeightedEntropyMiner(\n",
    "        select_filters=filters,\n",
    "        size=3,\n",
    "        display_name='weighted entropy miner',\n",
    "        model_name='yolov7',\n",
    "    )\n",
    "else:\n",
    "    miner = RandomMiner(\n",
    "        select_filters=filters,\n",
    "        size=3,\n",
    "        display_name='entropy miner',\n",
    "        model_name='yolov7',\n",
    "    )\n",
    "miner.run()\n",
    "\n",
    "miner_results = miner.get_results()\n",
    "\n",
    "print(miner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788fe8b-4740-4eb9-bc58-ff82c11fdc06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset = DioptraDataset()\n",
    "training_dataset.create('train')\n",
    "training_dataset.add_datapoints(miner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171b46c-8961-4222-936d-5fe11d553a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Do some training ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95ae7ef-7c52-4a4a-a261-798c6d7d0b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update the metadata now that our points have been uploaded to Dioptra\n",
    "# Begin by grabbing datapoints for the current task:\n",
    "filters = []\n",
    "datapoints_df = select_datapoints(filters=filters)\n",
    "\n",
    "metadata = []\n",
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc='Creating metadata')):\n",
    "    for i in range(len(paths)):\n",
    "        # grab matching datapoint id for the current image path\n",
    "        image = cv2.imread(paths[i])\n",
    "        image = letterbox(image, 640, stride=64, auto=True)[0]\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = torch.tensor(np.array([image.numpy()]))\n",
    "        _, _, height, width = image.shape\n",
    "\n",
    "        im_path = paths[i]\n",
    "        file_name = paths[i].split('/')[-1]\n",
    "        uri = os.path.join(img_dir, file_name)\n",
    "        for index, row in datapoints_df.iterrows():  \n",
    "            if row['metadata']['uri'] == uri:\n",
    "                row_id = index\n",
    "                break\n",
    "        datapoint_id = datapoints_df.iloc[row_id]['id']\n",
    "        metadata.append({'id': datapoint_id, 'image_metadata': {'uri': uri, 'width': width, 'height': height}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42ef46-65ae-45f2-ada5-b532e4021bdc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# active learning loop: \n",
    "num_iter = 5 # number of active learning steps\n",
    "for i in range(num_iter):\n",
    "        \n",
    "    #Run another inference\n",
    "    runner = TorchInferenceRunner(\n",
    "        model = model,\n",
    "        model_type='INSTANCE_SEGMENTATION',\n",
    "        model_name = 'yolov7_{}'.format(i),\n",
    "        data_transform = data_transformer,\n",
    "        datapoints_metadata=metadata,\n",
    "        logits_layer='model.128',\n",
    "        class_names=names,\n",
    "        logits_transform=partial(logits_transformer, model = model, pooler=pooler, hyp = hyp),\n",
    "        channel_last=False,\n",
    "    )\n",
    "    runner.max_batch_size = batch_size - 1\n",
    "    runner.run(dataloader)\n",
    "    \n",
    "    training_df = training_dataset.download_datapoints()\n",
    "    filters=[{\n",
    "        'left': 'predictions.model_name',\n",
    "        'op': '=',\n",
    "        'right': 'yolov7_{}'.format(i)\n",
    "    },{\n",
    "        'left': 'id',\n",
    "        'op': 'not in',\n",
    "        'right': training_df['id'].values.tolist() if len(training_df) > 0 else []\n",
    "    }]\n",
    "    if method == 'weighted_entropy':\n",
    "        miner = WeightedEntropyMiner(\n",
    "            select_filters=filters,\n",
    "            size=3,\n",
    "            display_name='weighted entropy miner',\n",
    "            model_name='yolov7_{}'.format(i),\n",
    "        )\n",
    "    else:\n",
    "        miner = RandomMiner(\n",
    "            select_filters=filters,\n",
    "            size=3,\n",
    "            display_name='entropy miner',\n",
    "            model_name='yolov7_{}'.format(i),\n",
    "        )\n",
    "    miner.run()\n",
    "\n",
    "    miner_results = miner.get_results()\n",
    "    training_dataset.add_datapoints(miner_results)\n",
    "    \n",
    "    ###### label points and begin training ######\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
