{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216d803-1a31-4f5c-809c-6820cfc55ea3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade roboflow pycocotools dioptra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c59e3-4721-405e-bea8-c863a279eaa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Setup credentials\n",
    "#\n",
    "####\n",
    "\n",
    "import os\n",
    "\n",
    "roboflow_api_key = '....'\n",
    "os.environ['DIOPTRA_API_KEY'] = '....'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '....'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1dca3d-cddd-45b6-9b3a-8ad5b1911461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Download Roboflow project\n",
    "#\n",
    "####\n",
    "\n",
    "import roboflow\n",
    "\n",
    "roboflow_project_name = '...'\n",
    "project_version = '...'\n",
    "\n",
    "rf = roboflow.Roboflow(api_key=roboflow_api_key)\n",
    "project = rf.project(roboflow_project_name)\n",
    "version = project.version(project_version)\n",
    "version.download('coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606795f6-1b67-4934-b07e-8495d6444982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Convert from Coco format to Dioptra format\n",
    "#\n",
    "####\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "#\n",
    "# Utility method to convert robo flow file path to gs uris\n",
    "#\n",
    "\n",
    "img_prefix  = 'gs://....'\n",
    "\n",
    "def process_img_path(img_path):\n",
    "    original_img_name = img_path.split('.')[0].replace('_jpg', '.jpg')\n",
    "    return f'{img_prefix}{original_img_name}'\n",
    "\n",
    "\n",
    "project_path = f'{version.project}-{version.version}'\n",
    "dataset_tag = {\n",
    "    'dataset_name': roboflow_project_name\n",
    "}\n",
    "\n",
    "my_records = []\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = os.path.join(project_path, split)\n",
    "    if not os.path.isdir(split_dir):\n",
    "        continue\n",
    "    annottation_file = os.path.join(split_dir, '_annotations.coco.json')\n",
    "    coco = COCO(annottation_file)\n",
    "\n",
    "    for image_id in coco.imgs.keys():\n",
    "        image_info = coco.imgs[image_id]\n",
    "        annotations = coco.loadAnns(coco.getAnnIds([image_id]))\n",
    "        my_annotations = [{\n",
    "            'task_type': 'INSTANCE_SEGMENTATION',\n",
    "            'bboxes': []\n",
    "        }]\n",
    "        for annotation in annotations:\n",
    "            category = coco.cats[annotation['category_id']]['name']\n",
    "            if 'segmentation' in annotation and annotation['segmentation'] != []:\n",
    "                my_annotation = {\n",
    "                    'class_name': category\n",
    "                }\n",
    "                my_annotation['coco_polygon'] = annotation['segmentation'][0]\n",
    "                my_annotations[0]['bboxes'].append(my_annotation)\n",
    "              \n",
    "        my_records.append({\n",
    "            'type': 'IMAGE',\n",
    "            'metadata': {\n",
    "                'uri': process_img_path(image_info['file_name']),\n",
    "                'width': image_info['width'],\n",
    "                'height': image_info['height'],\n",
    "            },\n",
    "            'groundtruths': my_annotations,\n",
    "            'tags': {\n",
    "                **dataset_tag,\n",
    "                'data_split': split\n",
    "            }\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c14d22-f82d-435d-8dd3-a80880d096d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Delete the lake (Optional)\n",
    "#\n",
    "###\n",
    "\n",
    "# from dioptra.lake.utils import delete_datapoints\n",
    "\n",
    "# delete_datapoints(\n",
    "#     [{'left': 'tags.name', 'op': '=', 'right': 'dataset_name'},\n",
    "#      {'left': 'tags.value', 'op': '=', 'right': roboflow_project_name}])\n",
    "\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54576d39-8918-4731-8c70-aa558a2088a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Upload to Lake ML\n",
    "#\n",
    "###\n",
    "\n",
    "from dioptra.lake.utils import upload_to_lake, wait_for_upload\n",
    "\n",
    "wait_for_upload(upload_to_lake(my_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accfe5a-7aa2-4c77-b89a-842d679d66f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Create a Dioptra dataset\n",
    "#\n",
    "###\n",
    "\n",
    "\n",
    "from dioptra.lake.datasets import Dataset as DioptraDataset\n",
    "\n",
    "my_dataset = DioptraDataset()\n",
    "my_dataset.get_or_create('chess board')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d444450-3c26-4074-a0a9-31b8295facc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Create a Random Miner\n",
    "#\n",
    "###\n",
    "\n",
    "\n",
    "from dioptra.miners.random_miner import RandomMiner\n",
    "\n",
    "my_miner = RandomMiner(\n",
    "    display_name='My random Miner',\n",
    "    select_filters=[\n",
    "        {'left': 'tags.name', 'op': '=', 'right': 'dataset_name'},\n",
    "        {'left': 'tags.value', 'op': '=', 'right': roboflow_project_name}],\n",
    "    size=10)\n",
    "my_miner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290fad1-56f8-4779-8cf4-86ac72bab65d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Add to the dataset and commit a new version\n",
    "#\n",
    "###\n",
    "\n",
    "my_dataset.add_datapoints(my_miner.get_results())\n",
    "my_dataset.commit('my first run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc635e-c7f1-4d1e-a7d7-b6bcfa486062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "#\n",
    "# Download the dataset, get the groundtruth and create a pytorch dataset\n",
    "#\n",
    "###\n",
    "\n",
    "from dioptra.lake.utils import select_groundtruths, join_on_datapoints\n",
    "from dioptra.lake.torch.object_store_datasets import ImageDataset\n",
    "\n",
    "datapoints_df = my_dataset.download_datapoints()\n",
    "gt_df = select_groundtruths(\n",
    "    [{'left': 'datapoint', 'op': 'in', 'right': list(my_dataset.download_datapoints()['id'])}],\n",
    "    fields=['*', 'bboxes.*'])\n",
    "\n",
    "joined_df = join_on_datapoints(datapoints_df, gt_df)\n",
    "\n",
    "my_torch_dataset = ImageDataset(joined_df)\n",
    "my_torch_dataset[0]['image']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
